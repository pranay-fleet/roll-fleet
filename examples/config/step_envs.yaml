all_response_pattern: ^(.*)$
action_pattern: <answer>(.*?)</answer>
think_action_pattern: <think>(.*?)</think>\s*<answer>(.*?)</answer>

max_tokens_per_step: 128
max_actions_per_traj: 10
default_history_length: 5
sokoban_format_penalty: -0.05
frozen_format_penalty: -0.01

env_manager_cls: roll.pipeline.agentic.env_manager.step_env_manager.StepEnvManager
custom_env:
  SimpleSokoban:
    env_type: sokoban
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config: # keys should be a subset of SokobanConfig
      action_pattern: ${action_pattern}
      max_steps: ${max_actions_per_traj}
      format_penalty: ${sokoban_format_penalty}
      dim_room: [6, 6]
      num_boxes: 1
  LargerSokoban:
    env_type: sokoban
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: roll.pipeline.agentic.env_manager.step_env_manager.StepEnvManager
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config:
      action_pattern: ${action_pattern}
      max_steps: ${max_actions_per_traj}
      format_penalty: ${sokoban_format_penalty}
      dim_room: [10, 10]
      num_boxes: 2
      search_depth: 10
  SokobanDifferentGridVocab:
    env_type: sokoban
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: roll.pipeline.agentic.env_manager.step_env_manager.StepEnvManager
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config: # keys should be a subset of SokobanConfig
      action_pattern: ${action_pattern}
      max_steps: ${max_actions_per_traj}
      format_penalty: ${sokoban_format_penalty}
      search_depth: 30
      dim_room: [6, 6]
      num_boxes: 1
      grid_lookup: { 0: "W", 1: ".", 2: "G", 3: "C", 4: "B", 5: "A", 6: "@" }
      grid_vocab: { "W": "wall", ".": "empty", "G": "target", "C": "box on target", "B": "box", "A": "player", "@": "player on target" }
  FrozenLake:
    env_type: frozen_lake
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: roll.pipeline.agentic.env_manager.step_env_manager.StepEnvManager
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config:
      action_pattern: ${action_pattern}
      max_steps: ${max_actions_per_traj}
      format_penalty: ${frozen_format_penalty}
      is_slippery: false
  FrozenLakeThink:
    env_type: frozen_lake
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: roll.pipeline.agentic.env_manager.step_env_manager.StepEnvManager
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config:
      action_pattern: ${think_action_pattern}
      max_steps: ${max_actions_per_traj}
      format_penalty: ${frozen_format_penalty}
      is_slippery: false
  WebShopEnv:
    env_type: webshop
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    use_thread_lock: true
    history_length: ${default_history_length}
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    max_env_step_concurrent: 5
    env_config:
      observation_mode: text
      max_steps: ${max_actions_per_traj}
      format_penalty: -0.05

agent_system_template: |
  You're a helpful assistant. You are a good game player. You are aiming to get high reward in the game.

agent_template: |
  ## Env Instruction: {env_instruction}
  
  ## State Description: 
  Prior to this step, you have completed {step_count} steps. 
  Recent History: Below are the most recent {history_length} observations, and your responses:
  [{history}]
  
  Current State:
  You are currently at step {current_step}. Your current observation is: [{current_observation}]
  
  ## Output Format Requirement: 
  1. output format is '<answer> [your answer] </answer>' with no extra text. 
  2. Max response length: {max_response_length} words (tokens).
  Decide the next action:
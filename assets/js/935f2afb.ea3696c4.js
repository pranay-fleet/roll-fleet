"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[8581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"English","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"DesignImplementation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AgenticPipeline","href":"/ROLL/docs/English/DesignImplementation/AgenticPipeline","docId":"English/DesignImplementation/AgenticPipeline"},{"type":"link","label":"RLVR Pipeline","href":"/ROLL/docs/English/DesignImplementation/RLVRPipeline","docId":"English/DesignImplementation/RLVRPipeline"}]},{"type":"category","label":"DevelopmentGuide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How to Add Support for a New Model","href":"/ROLL/docs/English/DevelopmentGuide/support_new_models_en","docId":"English/DevelopmentGuide/support_new_models_en"},{"type":"link","label":"Customer Env","href":"/ROLL/docs/English/DevelopmentGuide/customer_env_en","docId":"English/DevelopmentGuide/customer_env_en"},{"type":"link","label":"Prompt Generation Guide","href":"/ROLL/docs/English/DevelopmentGuide/prompt_intro_en","docId":"English/DevelopmentGuide/prompt_intro_en"}]},{"type":"category","label":"QuickStart","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Configuration Guide","href":"/ROLL/docs/English/QuickStart/config_guide","docId":"English/QuickStart/config_guide"},{"type":"link","label":"ROLL Configuration System Detailed Explanation","href":"/ROLL/docs/English/QuickStart/config_system","docId":"English/QuickStart/config_system"},{"type":"link","label":"ROLL Debugging Guide","href":"/ROLL/docs/English/QuickStart/debug_guide","docId":"English/QuickStart/debug_guide"},{"type":"link","label":"Image Provided","href":"/ROLL/docs/English/QuickStart/image_address","docId":"English/QuickStart/image_address"},{"type":"link","label":"Installation","href":"/ROLL/docs/English/QuickStart/installation","docId":"English/QuickStart/installation"},{"type":"link","label":"Quick Start: Multi-Node Deployment Guide","href":"/ROLL/docs/English/QuickStart/multi_nodes_quick_start","docId":"English/QuickStart/multi_nodes_quick_start"},{"type":"link","label":"Frequently Asked Questions (Q&A)","href":"/ROLL/docs/English/QuickStart/qa_issues","docId":"English/QuickStart/qa_issues"},{"type":"link","label":"Quick Start: Single-Node Deployment Guide","href":"/ROLL/docs/English/QuickStart/single_node_quick_start","docId":"English/QuickStart/single_node_quick_start"}]},{"type":"category","label":"UserGuide","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"agentic","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tool Use Guide","href":"/ROLL/docs/English/UserGuide/agentic/Tool_Use","docId":"English/UserGuide/agentic/Tool_Use"},{"type":"link","label":"StepWiseLearning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","href":"/ROLL/docs/English/UserGuide/agentic/agentic_GiGPO","docId":"English/UserGuide/agentic/agentic_GiGPO"},{"type":"link","label":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","href":"/ROLL/docs/English/UserGuide/agentic/agentic_StarPO","docId":"English/UserGuide/agentic/agentic_StarPO"}]},{"type":"link","label":"Agentic Asynchronous Parallel Rollout","href":"/ROLL/docs/English/UserGuide/agentic_async_parallel_rollout","docId":"English/UserGuide/agentic_async_parallel_rollout"},{"type":"category","label":"algorithms","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Group Relative Policy Optimization (GRPO)","href":"/ROLL/docs/English/UserGuide/algorithms/GRPO","docId":"English/UserGuide/algorithms/GRPO"},{"type":"link","label":"Group Sequence Policy Optimization (GSPO)","href":"/ROLL/docs/English/UserGuide/algorithms/GSPO","docId":"English/UserGuide/algorithms/GSPO"},{"type":"link","label":"Lite PPO","href":"/ROLL/docs/English/UserGuide/algorithms/LitePPO","docId":"English/UserGuide/algorithms/LitePPO"},{"type":"link","label":"Proximal Policy Optimization (PPO)","href":"/ROLL/docs/English/UserGuide/algorithms/PPO","docId":"English/UserGuide/algorithms/PPO"},{"type":"link","label":"RAFT++ (Reward rAnked Fine-Tuning)","href":"/ROLL/docs/English/UserGuide/algorithms/RAFT_Plus_Plus","docId":"English/UserGuide/algorithms/RAFT_Plus_Plus"},{"type":"link","label":"Reinforce++","href":"/ROLL/docs/English/UserGuide/algorithms/Reinforce_Plus_Plus","docId":"English/UserGuide/algorithms/Reinforce_Plus_Plus"},{"type":"link","label":"Reward Feedback Learning (Reward FL)","href":"/ROLL/docs/English/UserGuide/algorithms/Reward_FL","docId":"English/UserGuide/algorithms/Reward_FL"},{"type":"link","label":"TOPR (Tapered Off-Policy REINFORCE)","href":"/ROLL/docs/English/UserGuide/algorithms/TOPR","docId":"English/UserGuide/algorithms/TOPR"}]},{"type":"category","label":"ascend","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ROLL x Ascend","href":"/ROLL/docs/English/UserGuide/ascend/ascend_usage","docId":"English/UserGuide/ascend/ascend_usage"}]},{"type":"link","label":"Agentic Asynchronous Training Feature Usage Guide","href":"/ROLL/docs/English/UserGuide/async_training_agentic","docId":"English/UserGuide/async_training_agentic"},{"type":"category","label":"backend","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"DeepSpeed Training Backend Configuration Guide","href":"/ROLL/docs/English/UserGuide/backend/deepspeed","docId":"English/UserGuide/backend/deepspeed"},{"type":"link","label":"LoRA Fine-tuning Configuration Guide","href":"/ROLL/docs/English/UserGuide/backend/lora","docId":"English/UserGuide/backend/lora"},{"type":"link","label":"Megatron Inference and Training Backend Configuration Guide","href":"/ROLL/docs/English/UserGuide/backend/megatron","docId":"English/UserGuide/backend/megatron"},{"type":"link","label":"SGLang Inference Backend Configuration Guide","href":"/ROLL/docs/English/UserGuide/backend/sglang","docId":"English/UserGuide/backend/sglang"},{"type":"link","label":"vLLM Inference Backend Configuration Guide","href":"/ROLL/docs/English/UserGuide/backend/vllm","docId":"English/UserGuide/backend/vllm"}]},{"type":"link","label":"Checkpoint Saving and Resuming Guide","href":"/ROLL/docs/English/UserGuide/checkpoint_and_resume","docId":"English/UserGuide/checkpoint_and_resume"},{"type":"link","label":"ROLL Resource Configuration","href":"/ROLL/docs/English/UserGuide/device_mapping","docId":"English/UserGuide/device_mapping"},{"type":"link","label":"Converting MCoreAdapter Models to Hugging Face Format","href":"/ROLL/docs/English/UserGuide/megatron_convert_2_hf","docId":"English/UserGuide/megatron_convert_2_hf"},{"type":"link","label":"GPU Time-Division Multiplexing Control Guide","href":"/ROLL/docs/English/UserGuide/offload_reload_control","docId":"English/UserGuide/offload_reload_control"},{"type":"category","label":"pipeline","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Comprehensive Guide: Using the Agentic Part of ROLL","href":"/ROLL/docs/English/UserGuide/pipeline/agent_pipeline_start","docId":"English/UserGuide/pipeline/agent_pipeline_start"},{"type":"link","label":"Agentic Pipeline","href":"/ROLL/docs/English/UserGuide/pipeline/agentic_pipeline_start","docId":"English/UserGuide/pipeline/agentic_pipeline_start"},{"type":"link","label":"Distill Pipeline","href":"/ROLL/docs/English/UserGuide/pipeline/distill_pipeline_start","docId":"English/UserGuide/pipeline/distill_pipeline_start"},{"type":"link","label":"DPO Pipeline","href":"/ROLL/docs/English/UserGuide/pipeline/dpo_pipeline_start","docId":"English/UserGuide/pipeline/dpo_pipeline_start"},{"type":"link","label":"RLVR Pipeline","href":"/ROLL/docs/English/UserGuide/pipeline/rlvr_pipeline_start","docId":"English/UserGuide/pipeline/rlvr_pipeline_start"},{"type":"link","label":"RLVR Pipeline for VLM","href":"/ROLL/docs/English/UserGuide/pipeline/vl_rlvr_pipeline_start","docId":"English/UserGuide/pipeline/vl_rlvr_pipeline_start"}]},{"type":"link","label":"Trackers and Metrics","href":"/ROLL/docs/English/UserGuide/trackers_and_metrics","docId":"English/UserGuide/trackers_and_metrics"}]},{"type":"link","label":"start","href":"/ROLL/docs/English/start","docId":"English/start"}]},{"type":"link","label":"index","href":"/ROLL/docs/","docId":"index"},{"type":"category","label":"\u7b80\u4f53\u4e2d\u6587","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"\u4f7f\u7528\u6307\u5357","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"agentic","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tool Use \u4f7f\u7528\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/Tool_Use","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/Tool_Use"},{"type":"link","label":"StepWise Learning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_GiGPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_GiGPO"},{"type":"link","label":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_StarPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_StarPO"}]},{"type":"link","label":"Agentic \u5f02\u6b65\u5e76\u884c Rollout","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_parallel_rollout","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_parallel_rollout"},{"type":"link","label":"Agentic \u5f02\u6b65\u8bad\u7ec3\u529f\u80fd\u4f7f\u7528\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_training","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_training"},{"type":"category","label":"algorithms","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Group Relative Policy Optimization (GRPO)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GRPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GRPO"},{"type":"link","label":"Group Sequence Policy Optimization (GSPO)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GSPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GSPO"},{"type":"link","label":"Lite PPO","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/LitePPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/LitePPO"},{"type":"link","label":"Proximal Policy Optimization (PPO)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/PPO","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/PPO"},{"type":"link","label":"RAFT++ (Reward rAnked Fine-Tuning)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/RAFT_Plus_Plus","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/RAFT_Plus_Plus"},{"type":"link","label":"Reinforce++","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reinforce_Plus_Plus","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reinforce_Plus_Plus"},{"type":"link","label":"Reward Feedback Learning (Reward FL)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reward_FL","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reward_FL"},{"type":"link","label":"TOPR (Tapered Off-Policy REINFORCE)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/TOPR","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/TOPR"},{"type":"link","label":"RL options \u5927\u5168","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/rl_options","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/rl_options"}]},{"type":"category","label":"ascend","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ROLL x Ascend","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/ascend/ascend_usage","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/ascend/ascend_usage"}]},{"type":"category","label":"backend","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"DeepSpeed \u8bad\u7ec3\u540e\u7aef\u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/deepspeed","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/deepspeed"},{"type":"link","label":"fp8_rollout","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/fp8_rollout","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/fp8_rollout"},{"type":"link","label":"LoRA \u5fae\u8c03\u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/lora","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/lora"},{"type":"link","label":"Megatron \u63a8\u7406\u548c\u8bad\u7ec3\u540e\u7aef\u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/megatron","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/megatron"},{"type":"link","label":"SGLang \u63a8\u7406\u540e\u7aef\u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/sglang","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/sglang"},{"type":"link","label":"vLLM \u63a8\u7406\u540e\u7aef\u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/vllm","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/vllm"}]},{"type":"link","label":"\u68c0\u67e5\u70b9\u4fdd\u5b58\u4e0e\u6062\u590d\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/checkpoint_and_resume","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/checkpoint_and_resume"},{"type":"link","label":"ROLL \u8d44\u6e90\u914d\u7f6e","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/device_mapping","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/device_mapping"},{"type":"link","label":"MCoreAdapter \u6a21\u578b\u8f6c\u6362\u4e3a Hugging Face \u683c\u5f0f","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/megatron_convert_2_hf","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/megatron_convert_2_hf"},{"type":"link","label":"GPU \u65f6\u5206\u590d\u7528\u63a7\u5236\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/offload_reload_control","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/offload_reload_control"},{"type":"category","label":"pipeline","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Agentic Pipeline","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/agentic_pipeline_start","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/agentic_pipeline_start"},{"type":"link","label":"Distill Pipeline","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/distill_pipeline_start_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/distill_pipeline_start_cn"},{"type":"link","label":"DPOPipeline Quick Start","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/dpo_pipeline_start","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/dpo_pipeline_start"},{"type":"link","label":"RLVR \u6d41\u6c34\u7ebf","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/rlvr_pipeline_start","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/rlvr_pipeline_start"},{"type":"link","label":"SFTPipeline Quick Start","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/sft_pipeline_start","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/sft_pipeline_start"},{"type":"link","label":"VLM RLVR \u6d41\u6c34\u7ebf","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/vl_rlvr_pipeline_start","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/vl_rlvr_pipeline_start"}]},{"type":"link","label":"tracker\u548cmetrics","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/trackers_and_metrics","docId":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/trackers_and_metrics"}]},{"type":"category","label":"\u5feb\u901f\u5f00\u59cb","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ROLL \u914d\u7f6e\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_guide_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_guide_cn"},{"type":"link","label":"ROLL \u914d\u7f6e\u7cfb\u7edf\u8be6\u89e3","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_system","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_system"},{"type":"link","label":"ROLL \u8c03\u8bd5\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/debug_guide","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/debug_guide"},{"type":"link","label":"\u955c\u50cf\u5730\u5740","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/image_address","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/image_address"},{"type":"link","label":"\u5b89\u88c5\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/installation","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/installation"},{"type":"link","label":"\u5feb\u901f\u4e0a\u624b\uff1a\u591a\u8282\u70b9\u90e8\u7f72\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/multi_nodes_quick_start_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/multi_nodes_quick_start_cn"},{"type":"link","label":"\u5e38\u89c1\u95ee\u9898\u89e3\u7b54 (Q&A)","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/qa_issues","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/qa_issues"},{"type":"link","label":"\u5feb\u901f\u4e0a\u624b\uff1a\u5355\u673a\u7248\u90e8\u7f72\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/single_node_quick_start_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/single_node_quick_start_cn"}]},{"type":"category","label":"\u6027\u80fd\u8c03\u4f18\u6307\u5357","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"megatron\u8c03\u4f18\u5efa\u8bae","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/megatron_config_simple_guide","docId":"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/megatron_config_simple_guide"},{"type":"link","label":"ROLL\u914d\u7f6e\u8c03\u4f18","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/roll_config_tune_guide","docId":"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/roll_config_tune_guide"}]},{"type":"category","label":"\u6269\u5c55\u5f00\u53d1\u624b\u518c","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\u5982\u4f55\u652f\u6301\u65b0\u6a21\u578b","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/support_new_models_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/support_new_models_cn"},{"type":"link","label":"\u81ea\u5b9a\u4e49Env","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_env_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_env_cn"},{"type":"link","label":"custom_pipeline","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_pipeline","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_pipeline"},{"type":"link","label":"\u81ea\u5b9a\u4e49Reward\xa0Worker","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_cn"},{"type":"link","label":"custom_reward_worker","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_worker","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_worker"},{"type":"link","label":"\u591a\u8f6e\u4ea4\u4e92EnvManager\u6269\u5c55","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/multi_turn_env_manager","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/multi_turn_env_manager"},{"type":"link","label":"Prompt\u751f\u6210\u6307\u5357","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/prompt_intro_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/prompt_intro_cn"}]},{"type":"category","label":"\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AgenticPipeline","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/AgenticPipeline_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/AgenticPipeline_cn"},{"type":"link","label":"RLVR\xa0Pipeline","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/RLVRPipeline_cn","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/RLVRPipeline_cn"},{"type":"link","label":"Agentic\u5f02\u6b65\u8bad\u7ec3\u8bbe\u8ba1","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_async_traning_design","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_async_traning_design"},{"type":"link","label":"\u591a\u8f6e\u4ea4\u4e92EnvManager\u8bbe\u8ba1","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_rollout_env_manager","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_rollout_env_manager"},{"type":"link","label":"\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/resource_system","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/resource_system"},{"type":"link","label":"RLVR\u6837\u672c\u7ea7\u5f02\u6b65\u5e76\u884c\u52a8\u6001\u91c7\u6837","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/rlvr_dynamic_sampling","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/rlvr_dynamic_sampling"},{"type":"link","label":"Strategy \u7edf\u4e00\u5404Backend\u8bbe\u8ba1","href":"/ROLL/docs/\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/strategy_backend_design","docId":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/strategy_backend_design"}]}]}]},"docs":{"English/DesignImplementation/AgenticPipeline":{"id":"English/DesignImplementation/AgenticPipeline","title":"AgenticPipeline","description":"Agentic Pipeline Architecture Diagram","sidebar":"tutorialSidebar"},"English/DesignImplementation/RLVRPipeline":{"id":"English/DesignImplementation/RLVRPipeline","title":"RLVR Pipeline","description":"RLVR Pipeline (Reinforcement Learning with Verifiable Rewards Pipeline) is a core component in the ROLL framework, specifically designed as an efficient distributed training pipeline for large language model reinforcement learning. Through virtual reward mechanisms, this pipeline can significantly improve LLM performance on key tasks such as complex reasoning, code generation, and mathematical calculations.","sidebar":"tutorialSidebar"},"English/DevelopmentGuide/customer_env_en":{"id":"English/DevelopmentGuide/customer_env_en","title":"Customer Env","description":"Reinforcement Learning Environment","sidebar":"tutorialSidebar"},"English/DevelopmentGuide/prompt_intro_en":{"id":"English/DevelopmentGuide/prompt_intro_en","title":"Prompt Generation Guide","description":"In the architecture of Large Language Model (LLM)-based Reinforcement Learning Agents, the Prompt serves as the sole medium for LLMs to interact with the environment. Unlike traditional agents that directly receive numerical states or output discrete action IDs, LLMs \\"perceive\\" the environment (observations) and \\"express\\" their decisions (actions) through prompts in text format.","sidebar":"tutorialSidebar"},"English/DevelopmentGuide/support_new_models_en":{"id":"English/DevelopmentGuide/support_new_models_en","title":"How to Add Support for a New Model","description":"To integrate a new model into ROLL, you must supply:","sidebar":"tutorialSidebar"},"English/QuickStart/config_guide":{"id":"English/QuickStart/config_guide","title":"Configuration Guide","description":"Pipeline Config","sidebar":"tutorialSidebar"},"English/QuickStart/config_system":{"id":"English/QuickStart/config_system","title":"ROLL Configuration System Detailed Explanation","description":"The ROLL framework adopts a structured configuration system that defines experimental parameters through YAML files. This document will provide a detailed introduction to ROLL\'s configuration design, helping new users understand the framework\'s configuration structure and extension methods.","sidebar":"tutorialSidebar"},"English/QuickStart/debug_guide":{"id":"English/QuickStart/debug_guide","title":"ROLL Debugging Guide","description":"When developing and using the ROLL framework, debugging is an essential step. This document will introduce several effective debugging methods to help you quickly locate and resolve issues.","sidebar":"tutorialSidebar"},"English/QuickStart/image_address":{"id":"English/QuickStart/image_address","title":"Image Provided","description":"We provide pre-built Docker images for a quick start (Links will be updated):","sidebar":"tutorialSidebar"},"English/QuickStart/installation":{"id":"English/QuickStart/installation","title":"Installation","description":"\ud83d\udc33 Install from Docker","sidebar":"tutorialSidebar"},"English/QuickStart/multi_nodes_quick_start":{"id":"English/QuickStart/multi_nodes_quick_start","title":"Quick Start: Multi-Node Deployment Guide","description":"Environment Preparation","sidebar":"tutorialSidebar"},"English/QuickStart/qa_issues":{"id":"English/QuickStart/qa_issues","title":"Frequently Asked Questions (Q&A)","description":"This document compiles common issues that may be encountered when using the ROLL framework and their solutions.","sidebar":"tutorialSidebar"},"English/QuickStart/single_node_quick_start":{"id":"English/QuickStart/single_node_quick_start","title":"Quick Start: Single-Node Deployment Guide","description":"Environment Preparation","sidebar":"tutorialSidebar"},"English/start":{"id":"English/start","title":"start","description":"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80","sidebar":"tutorialSidebar"},"English/UserGuide/agentic_async_parallel_rollout":{"id":"English/UserGuide/agentic_async_parallel_rollout","title":"Agentic Asynchronous Parallel Rollout","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/agentic/agentic_GiGPO":{"id":"English/UserGuide/agentic/agentic_GiGPO","title":"StepWiseLearning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/agentic/agentic_StarPO":{"id":"English/UserGuide/agentic/agentic_StarPO","title":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/agentic/Tool_Use":{"id":"English/UserGuide/agentic/Tool_Use","title":"Tool Use Guide","description":"Overview","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/GRPO":{"id":"English/UserGuide/algorithms/GRPO","title":"Group Relative Policy Optimization (GRPO)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/GSPO":{"id":"English/UserGuide/algorithms/GSPO","title":"Group Sequence Policy Optimization (GSPO)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/LitePPO":{"id":"English/UserGuide/algorithms/LitePPO","title":"Lite PPO","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/PPO":{"id":"English/UserGuide/algorithms/PPO","title":"Proximal Policy Optimization (PPO)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/RAFT_Plus_Plus":{"id":"English/UserGuide/algorithms/RAFT_Plus_Plus","title":"RAFT++ (Reward rAnked Fine-Tuning)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/Reinforce_Plus_Plus":{"id":"English/UserGuide/algorithms/Reinforce_Plus_Plus","title":"Reinforce++","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/Reward_FL":{"id":"English/UserGuide/algorithms/Reward_FL","title":"Reward Feedback Learning (Reward FL)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/algorithms/TOPR":{"id":"English/UserGuide/algorithms/TOPR","title":"TOPR (Tapered Off-Policy REINFORCE)","description":"Introduction","sidebar":"tutorialSidebar"},"English/UserGuide/ascend/ascend_usage":{"id":"English/UserGuide/ascend/ascend_usage","title":"ROLL x Ascend","description":"Last updated: 09/28/2025.","sidebar":"tutorialSidebar"},"English/UserGuide/async_training_agentic":{"id":"English/UserGuide/async_training_agentic","title":"Agentic Asynchronous Training Feature Usage Guide","description":"The ROLL framework supports Agentic asynchronous training functionality, which can significantly improve training efficiency. This document will provide detailed instructions on how to use this feature.","sidebar":"tutorialSidebar"},"English/UserGuide/backend/deepspeed":{"id":"English/UserGuide/backend/deepspeed","title":"DeepSpeed Training Backend Configuration Guide","description":"DeepSpeed is Microsoft\'s efficient deep learning optimization library that provides memory optimization, distributed training, and performance optimization features. This document will provide detailed instructions on how to configure and use the DeepSpeed training backend in the ROLL framework.","sidebar":"tutorialSidebar"},"English/UserGuide/backend/lora":{"id":"English/UserGuide/backend/lora","title":"LoRA Fine-tuning Configuration Guide","description":"LoRA (Low-Rank Adaptation) is an efficient parameter-efficient fine-tuning method that achieves parameter-efficient fine-tuning by adding low-rank matrices to pre-trained models. This document will provide detailed instructions on how to configure and use LoRA fine-tuning in the ROLL framework.","sidebar":"tutorialSidebar"},"English/UserGuide/backend/megatron":{"id":"English/UserGuide/backend/megatron","title":"Megatron Inference and Training Backend Configuration Guide","description":"Megatron is NVIDIA\'s large-scale language model training and inference framework that supports efficient distributed training and inference. This document will provide detailed instructions on how to configure and use the Megatron backend in the ROLL framework.","sidebar":"tutorialSidebar"},"English/UserGuide/backend/sglang":{"id":"English/UserGuide/backend/sglang","title":"SGLang Inference Backend Configuration Guide","description":"SGLang is a fast and easy-to-use inference engine, particularly suitable for inference tasks of large-scale language models. This document will provide detailed instructions on how to configure and use the SGLang inference backend in the ROLL framework.","sidebar":"tutorialSidebar"},"English/UserGuide/backend/vllm":{"id":"English/UserGuide/backend/vllm","title":"vLLM Inference Backend Configuration Guide","description":"vLLM is a fast and easy-to-use large language model inference library that efficiently manages attention key-value cache through PagedAttention technology. This document will provide detailed instructions on how to configure and use the vLLM inference backend in the ROLL framework.","sidebar":"tutorialSidebar"},"English/UserGuide/checkpoint_and_resume":{"id":"English/UserGuide/checkpoint_and_resume","title":"Checkpoint Saving and Resuming Guide","description":"In the ROLL framework, the checkpoint mechanism allows you to save the model state during training so that you can resume training when needed. This document will provide detailed instructions on how to configure and use the checkpoint saving and resuming functionality.","sidebar":"tutorialSidebar"},"English/UserGuide/device_mapping":{"id":"English/UserGuide/device_mapping","title":"ROLL Resource Configuration","description":"In the ROLL framework, resource settings are specified through the device_mapping parameter in YAML configuration files to determine which GPU devices each worker uses. This document will provide detailed instructions on how to configure resources, including colocated and disaggregated modes, multi-role resource configuration, and how worker counts are calculated.","sidebar":"tutorialSidebar"},"English/UserGuide/megatron_convert_2_hf":{"id":"English/UserGuide/megatron_convert_2_hf","title":"Converting MCoreAdapter Models to Hugging Face Format","description":"MCoreAdapter provides tools for converting between Megatron(McoreAdapter) and Hugging Face model formats. This document will guide you on how to convert a trained Megatron model to Hugging Face format for use in other projects.","sidebar":"tutorialSidebar"},"English/UserGuide/offload_reload_control":{"id":"English/UserGuide/offload_reload_control","title":"GPU Time-Division Multiplexing Control Guide","description":"The ROLL framework implements GPU time-division multiplexing functionality, which allows flexible sharing of GPU resources between different roles through offload/reload capabilities. This document will provide detailed instructions on how to use this feature.","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/agent_pipeline_start":{"id":"English/UserGuide/pipeline/agent_pipeline_start","title":"Comprehensive Guide: Using the Agentic Part of ROLL","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/agentic_pipeline_start":{"id":"English/UserGuide/pipeline/agentic_pipeline_start","title":"Agentic Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/distill_pipeline_start":{"id":"English/UserGuide/pipeline/distill_pipeline_start","title":"Distill Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/dpo_pipeline_start":{"id":"English/UserGuide/pipeline/dpo_pipeline_start","title":"DPO Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/rlvr_pipeline_start":{"id":"English/UserGuide/pipeline/rlvr_pipeline_start","title":"RLVR Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/pipeline/vl_rlvr_pipeline_start":{"id":"English/UserGuide/pipeline/vl_rlvr_pipeline_start","title":"RLVR Pipeline for VLM","description":"Table of Contents","sidebar":"tutorialSidebar"},"English/UserGuide/trackers_and_metrics":{"id":"English/UserGuide/trackers_and_metrics","title":"Trackers and Metrics","description":"The ROLL framework supports multiple experiment tracking tools to help you monitor and analyze the training process. This document will provide detailed instructions on how to configure and use these trackers.","sidebar":"tutorialSidebar"},"index":{"id":"index","title":"index","description":"","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_parallel_rollout":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_parallel_rollout","title":"Agentic \u5f02\u6b65\u5e76\u884c Rollout","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_training":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic_async_training","title":"Agentic \u5f02\u6b65\u8bad\u7ec3\u529f\u80fd\u4f7f\u7528\u6307\u5357","description":"ROLL \u6846\u67b6\u652f\u6301 Agentic \u5f02\u6b65\u8bad\u7ec3\u529f\u80fd\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528\u8fd9\u4e00\u529f\u80fd\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_GiGPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_GiGPO","title":"StepWise Learning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_StarPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/agentic_StarPO","title":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/Tool_Use":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/agentic/Tool_Use","title":"Tool Use \u4f7f\u7528\u6307\u5357","description":"\u6982\u8ff0","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GRPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GRPO","title":"Group Relative Policy Optimization (GRPO)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GSPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/GSPO","title":"Group Sequence Policy Optimization (GSPO)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/LitePPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/LitePPO","title":"Lite PPO","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/PPO":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/PPO","title":"Proximal Policy Optimization (PPO)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/RAFT_Plus_Plus":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/RAFT_Plus_Plus","title":"RAFT++ (Reward rAnked Fine-Tuning)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reinforce_Plus_Plus":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reinforce_Plus_Plus","title":"Reinforce++","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reward_FL":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/Reward_FL","title":"Reward Feedback Learning (Reward FL)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/rl_options":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/rl_options","title":"RL options \u5927\u5168","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/TOPR":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/algorithms/TOPR","title":"TOPR (Tapered Off-Policy REINFORCE)","description":"\u7b80\u4ecb","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/ascend/ascend_usage":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/ascend/ascend_usage","title":"ROLL x Ascend","description":"Last updated: 09/28/2025.","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/deepspeed":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/deepspeed","title":"DeepSpeed \u8bad\u7ec3\u540e\u7aef\u914d\u7f6e\u6307\u5357","description":"DeepSpeed \u662f\u5fae\u8f6f\u5f00\u53d1\u7684\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u5e93\uff0c\u63d0\u4f9b\u4e86\u5185\u5b58\u4f18\u5316\u3001\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u6027\u80fd\u4f18\u5316\u7b49\u529f\u80fd\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 ROLL \u6846\u67b6\u4e2d\u914d\u7f6e\u548c\u4f7f\u7528 DeepSpeed \u8bad\u7ec3\u540e\u7aef\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/fp8_rollout":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/fp8_rollout","title":"fp8_rollout","description":"","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/lora":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/lora","title":"LoRA \u5fae\u8c03\u914d\u7f6e\u6307\u5357","description":"LoRA (Low-Rank Adaptation) \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u6dfb\u52a0\u4f4e\u79e9\u77e9\u9635\u6765\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 ROLL \u6846\u67b6\u4e2d\u914d\u7f6e\u548c\u4f7f\u7528 LoRA \u5fae\u8c03\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/megatron":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/megatron","title":"Megatron \u63a8\u7406\u548c\u8bad\u7ec3\u540e\u7aef\u914d\u7f6e\u6307\u5357","description":"Megatron \u662f NVIDIA \u5f00\u53d1\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u6846\u67b6\uff0c\u652f\u6301\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 ROLL \u6846\u67b6\u4e2d\u914d\u7f6e\u548c\u4f7f\u7528 Megatron \u540e\u7aef\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/sglang":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/sglang","title":"SGLang \u63a8\u7406\u540e\u7aef\u914d\u7f6e\u6307\u5357","description":"SGLang \u662f\u4e00\u4e2a\u5feb\u901f\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4efb\u52a1\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 ROLL \u6846\u67b6\u4e2d\u914d\u7f6e\u548c\u4f7f\u7528 SGLang \u63a8\u7406\u540e\u7aef\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/vllm":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/backend/vllm","title":"vLLM \u63a8\u7406\u540e\u7aef\u914d\u7f6e\u6307\u5357","description":"vLLM \u662f\u4e00\u4e2a\u5feb\u901f\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5e93\uff0c\u901a\u8fc7 PagedAttention \u6280\u672f\u9ad8\u6548\u7ba1\u7406\u6ce8\u610f\u529b\u952e\u503c\u7f13\u5b58\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 ROLL \u6846\u67b6\u4e2d\u914d\u7f6e\u548c\u4f7f\u7528 vLLM \u63a8\u7406\u540e\u7aef\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/checkpoint_and_resume":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/checkpoint_and_resume","title":"\u68c0\u67e5\u70b9\u4fdd\u5b58\u4e0e\u6062\u590d\u6307\u5357","description":"\u5728 ROLL \u6846\u67b6\u4e2d\uff0c\u68c0\u67e5\u70b9\uff08Checkpoint\uff09\u673a\u5236\u5141\u8bb8\u60a8\u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6a21\u578b\u72b6\u6001\uff0c\u4ee5\u4fbf\u5728\u9700\u8981\u65f6\u6062\u590d\u8bad\u7ec3\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528\u68c0\u67e5\u70b9\u4fdd\u5b58\u4e0e\u6062\u590d\u529f\u80fd\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/device_mapping":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/device_mapping","title":"ROLL \u8d44\u6e90\u914d\u7f6e","description":"\u5728 ROLL \u6846\u67b6\u4e2d\uff0c\u8d44\u6e90\u8bbe\u7f6e\u662f\u901a\u8fc7 YAML \u914d\u7f6e\u6587\u4ef6\u4e2d\u7684 device_mapping \u53c2\u6570\u6765\u6307\u5b9a\u6bcf\u4e2a worker \u4f7f\u7528\u54ea\u4e9b GPU \u8bbe\u5907\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u914d\u7f6e\u8d44\u6e90\uff0c\u5305\u62ec\u5171\u7f6e\u548c\u5206\u79bb\u6a21\u5f0f\u3001\u591a\u89d2\u8272\u8d44\u6e90\u914d\u7f6e\u4ee5\u53ca worker \u6570\u91cf\u7684\u8ba1\u7b97\u65b9\u5f0f\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/megatron_convert_2_hf":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/megatron_convert_2_hf","title":"MCoreAdapter \u6a21\u578b\u8f6c\u6362\u4e3a Hugging Face \u683c\u5f0f","description":"MCoreAdapter \u63d0\u4f9b\u4e86\u5728 Megatron(McoreAdapter) \u548c Hugging Face \u6a21\u578b\u683c\u5f0f\u4e4b\u95f4\u8fdb\u884c\u8f6c\u6362\u7684\u5de5\u5177\u3002\u672c\u6587\u6863\u5c06\u6307\u5bfc\u60a8\u5982\u4f55\u5c06\u8bad\u7ec3\u597d\u7684 Megatron(McoreAdapter) \u6a21\u578b\u8f6c\u6362\u4e3a Hugging Face \u683c\u5f0f\uff0c\u4ee5\u4fbf\u5728\u5176\u4ed6\u9879\u76ee\u4e2d\u4f7f\u7528\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/offload_reload_control":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/offload_reload_control","title":"GPU \u65f6\u5206\u590d\u7528\u63a7\u5236\u6307\u5357","description":"ROLL \u6846\u67b6\u5b9e\u73b0\u4e86 GPU \u65f6\u5206\u590d\u7528\u529f\u80fd\uff0c\u901a\u8fc7 offload/reload \u80fd\u529b\uff0c\u53ef\u4ee5\u5728\u4e0d\u540c\u89d2\u8272\u95f4\u7075\u6d3b\u5171\u4eab GPU \u8d44\u6e90\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528\u8fd9\u4e00\u529f\u80fd\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/agentic_pipeline_start":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/agentic_pipeline_start","title":"Agentic Pipeline","description":"\u76ee\u5f55","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/distill_pipeline_start_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/distill_pipeline_start_cn","title":"Distill Pipeline","description":"\u76ee\u5f55","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/dpo_pipeline_start":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/dpo_pipeline_start","title":"DPOPipeline Quick Start","description":"\u76ee\u5f55","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/rlvr_pipeline_start":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/rlvr_pipeline_start","title":"RLVR \u6d41\u6c34\u7ebf","description":"\u76ee\u5f55","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/sft_pipeline_start":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/sft_pipeline_start","title":"SFTPipeline Quick Start","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/vl_rlvr_pipeline_start":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/pipeline/vl_rlvr_pipeline_start","title":"VLM RLVR \u6d41\u6c34\u7ebf","description":"- VLM RLVR \u6d41\u6c34\u7ebf","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/trackers_and_metrics":{"id":"\u7b80\u4f53\u4e2d\u6587/\u4f7f\u7528\u6307\u5357/trackers_and_metrics","title":"tracker\u548cmetrics","description":"ROLL \u6846\u67b6\u652f\u6301\u591a\u79cd\u5b9e\u9a8ctrack\u5de5\u5177\uff0c\u5e2e\u52a9\u60a8\u76d1\u63a7\u548c\u5206\u6790\u8bad\u7ec3\u8fc7\u7a0b\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528\u8fd9\u4e9b\u8ddf\u8e2a\u5668\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_guide_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_guide_cn","title":"ROLL \u914d\u7f6e\u6307\u5357","description":"ROLL \u6846\u67b6\u901a\u8fc7 YAML \u914d\u7f6e\u6587\u4ef6\u6765\u5b9a\u4e49\u5b9e\u9a8c\u53c2\u6570\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u914d\u7f6e\u9879\u7684\u542b\u4e49\u548c\u4f7f\u7528\u65b9\u6cd5\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_system":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/config_system","title":"ROLL \u914d\u7f6e\u7cfb\u7edf\u8be6\u89e3","description":"ROLL \u6846\u67b6\u91c7\u7528\u4e86\u4e00\u5957\u7ed3\u6784\u5316\u7684\u914d\u7f6e\u7cfb\u7edf\uff0c\u901a\u8fc7 YAML \u6587\u4ef6\u5b9a\u4e49\u5b9e\u9a8c\u53c2\u6570\u3002\u672c\u6587\u6863\u5c06\u8be6\u7ec6\u4ecb\u7ecd ROLL \u7684\u914d\u7f6e\u8bbe\u8ba1\uff0c\u5e2e\u52a9\u65b0\u7528\u6237\u7406\u89e3\u6846\u67b6\u7684\u914d\u7f6e\u7ed3\u6784\u548c\u6269\u5c55\u65b9\u5f0f\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/debug_guide":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/debug_guide","title":"ROLL \u8c03\u8bd5\u6307\u5357","description":"\u5728\u5f00\u53d1\u548c\u4f7f\u7528 ROLL \u6846\u67b6\u65f6\uff0c\u8c03\u8bd5\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u73af\u8282\u3002\u672c\u6587\u6863\u5c06\u4ecb\u7ecd\u51e0\u79cd\u6709\u6548\u7684\u8c03\u8bd5\u65b9\u6cd5\uff0c\u5e2e\u52a9\u60a8\u5feb\u901f\u5b9a\u4f4d\u548c\u89e3\u51b3\u95ee\u9898\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/image_address":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/image_address","title":"\u955c\u50cf\u5730\u5740","description":"\u6211\u4eec\u63d0\u4f9b\u4e86\u9884\u6784\u5efa\u7684Docker\u955c\u50cf\u4ee5\u4fbf\u5feb\u901f\u5f00\u59cb\uff1a","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/installation":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/installation","title":"\u5b89\u88c5\u6307\u5357","description":"\ud83d\udc33 \u4f7f\u7528 Docker \u5b89\u88c5","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/multi_nodes_quick_start_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/multi_nodes_quick_start_cn","title":"\u5feb\u901f\u4e0a\u624b\uff1a\u591a\u8282\u70b9\u90e8\u7f72\u6307\u5357","description":"\u51c6\u5907\u73af\u5883","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/qa_issues":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/qa_issues","title":"\u5e38\u89c1\u95ee\u9898\u89e3\u7b54 (Q&A)","description":"\u672c\u6587\u6863\u6574\u7406\u4e86\u4f7f\u7528 ROLL \u6846\u67b6\u65f6\u53ef\u80fd\u9047\u5230\u7684\u5e38\u89c1\u95ee\u9898\u53ca\u5176\u89e3\u51b3\u65b9\u6848\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/single_node_quick_start_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u5feb\u901f\u5f00\u59cb/single_node_quick_start_cn","title":"\u5feb\u901f\u4e0a\u624b\uff1a\u5355\u673a\u7248\u90e8\u7f72\u6307\u5357","description":"\u51c6\u5907\u73af\u5883","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/megatron_config_simple_guide":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/megatron_config_simple_guide","title":"megatron\u8c03\u4f18\u5efa\u8bae","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/roll_config_tune_guide":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6027\u80fd\u8c03\u4f18\u6307\u5357/roll_config_tune_guide","title":"ROLL\u914d\u7f6e\u8c03\u4f18","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_env_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_env_cn","title":"\u81ea\u5b9a\u4e49Env","description":"\u5f3a\u5316\u5b66\u4e60Env","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_pipeline":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_pipeline","title":"custom_pipeline","description":"","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_cn","title":"\u81ea\u5b9a\u4e49Reward\xa0Worker","description":"Reward\u6838\u5fc3\u6982\u5ff5","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_worker":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/custom_reward_worker","title":"custom_reward_worker","description":"","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/multi_turn_env_manager":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/multi_turn_env_manager","title":"\u591a\u8f6e\u4ea4\u4e92EnvManager\u6269\u5c55","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/prompt_intro_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/prompt_intro_cn","title":"Prompt\u751f\u6210\u6307\u5357","description":"\u5728\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5f3a\u5316\u5b66\u4e60 Agent \u4f53\u7cfb\u4e2d\uff0cPrompt\xa0\u662f LLM \u4e0e\u73af\u5883\u8fdb\u884c\u4ea4\u4e92\u7684\u552f\u4e00\u4ecb\u8d28\u3002LLM \u4e0d\u50cf\u4f20\u7edf Agent \u90a3\u6837\u76f4\u63a5\u63a5\u6536\u6570\u503c\u72b6\u6001\u6216\u8f93\u51fa\u79bb\u6563\u52a8\u4f5c ID\uff0c\u800c\u662f\u901a\u8fc7\u6587\u672c\u5f62\u5f0f\u7684 Prompt \u6765\u201c\u611f\u77e5\u201d\u73af\u5883\uff08\u89c2\u6d4b\uff09\u5e76\u201c\u8868\u8fbe\u201d\u5176\u51b3\u7b56\uff08\u52a8\u4f5c\uff09\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/support_new_models_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u6269\u5c55\u5f00\u53d1\u624b\u518c/support_new_models_cn","title":"\u5982\u4f55\u652f\u6301\u65b0\u6a21\u578b","description":"\u8981\u5728 ROLL \u4e2d\u96c6\u6210\u4e00\u4e2a\u65b0\u6a21\u578b\uff0c\u9700\u8981\u652f\u6301\uff1a","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_async_traning_design":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_async_traning_design","title":"Agentic\u5f02\u6b65\u8bad\u7ec3\u8bbe\u8ba1","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_rollout_env_manager":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/agentic_rollout_env_manager","title":"\u591a\u8f6e\u4ea4\u4e92EnvManager\u8bbe\u8ba1","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/AgenticPipeline_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/AgenticPipeline_cn","title":"AgenticPipeline","description":"Agentic\xa0Pipeline\xa0\u67b6\u6784\u56fe","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/resource_system":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/resource_system","title":"\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/rlvr_dynamic_sampling":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/rlvr_dynamic_sampling","title":"RLVR\u6837\u672c\u7ea7\u5f02\u6b65\u5e76\u884c\u52a8\u6001\u91c7\u6837","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/RLVRPipeline_cn":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/RLVRPipeline_cn","title":"RLVR\xa0Pipeline","description":"RLVR\xa0Pipeline\xa0(Reinforcement\xa0Learning\xa0with\xa0Verifiable\xa0Rewards\xa0Pipeline)\xa0\u662f\xa0ROLL\xa0\u6846\u67b6\u4e2d\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4e13\u95e8\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u800c\u8bbe\u8ba1\u7684\u9ad8\u6548\u5206\u5e03\u5f0f\u8bad\u7ec3\u7ba1\u9053\u3002\u8be5\u7ba1\u9053\u901a\u8fc7\u865a\u62df\u5956\u52b1\u673a\u5236\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u590d\u6742\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u3001\u6570\u5b66\u8ba1\u7b97\u7b49\u5173\u952e\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002","sidebar":"tutorialSidebar"},"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/strategy_backend_design":{"id":"\u7b80\u4f53\u4e2d\u6587/\u8bbe\u8ba1\u5b9e\u73b0\u6587\u6863/strategy_backend_design","title":"Strategy \u7edf\u4e00\u5404Backend\u8bbe\u8ba1","description":"\u65bd\u5de5\u4e2d...","sidebar":"tutorialSidebar"}}}')}}]);
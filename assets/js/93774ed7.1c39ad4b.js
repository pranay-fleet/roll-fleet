"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[9171],{3856:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var a=t(8168),r=(t(6540),t(5680));const o={sidebar_position:3},i="How to Add Support for a New Model",l={unversionedId:"English/DevelopmentGuide/support_new_models_en",id:"English/DevelopmentGuide/support_new_models_en",title:"How to Add Support for a New Model",description:"To integrate a new model into ROLL, you must supply:",source:"@site/docs/English/DevelopmentGuide/support_new_models_en.md",sourceDirName:"English/DevelopmentGuide",slug:"/English/DevelopmentGuide/support_new_models_en",permalink:"/ROLL/docs/English/DevelopmentGuide/support_new_models_en",draft:!1,editUrl:"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/English/DevelopmentGuide/support_new_models_en.md",tags:[],version:"current",lastUpdatedAt:1761384892,formattedLastUpdatedAt:"Oct 25, 2025",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"RLVR Pipeline",permalink:"/ROLL/docs/English/DesignImplementation/RLVRPipeline"},next:{title:"Customer Env",permalink:"/ROLL/docs/English/DevelopmentGuide/customer_env_en"}},s={},p=[{value:"1. Inference Strategies",id:"1-inference-strategies",level:2},{value:"1.1 <code>vllm</code>",id:"11-vllm",level:3},{value:"1.2 <code>sglang</code>",id:"12-sglang",level:3},{value:"2. Training Strategies",id:"2-training-strategies",level:2},{value:"2.1 <code>DeepSpeed</code>",id:"21-deepspeed",level:3},{value:"2.2 <code>Megatron</code>",id:"22-megatron",level:3},{value:"1. For Standard Transformer Models",id:"1-for-standard-transformer-models",level:4},{value:"Registering a New Template",id:"registering-a-new-template",level:5},{value:"2. For Models with Custom Components",id:"2-for-models-with-custom-components",level:4}],g={toc:p},m="wrapper";function d({components:e,...n}){return(0,r.yg)(m,(0,a.A)({},g,n,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"how-to-add-support-for-a-new-model"},"How to Add Support for a New Model"),(0,r.yg)("p",null,"To integrate a new model into ",(0,r.yg)("strong",{parentName:"p"},"ROLL"),", you must supply:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"at least one ",(0,r.yg)("strong",{parentName:"li"},"inference")," implementation, and  "),(0,r.yg)("li",{parentName:"ol"},"at least one ",(0,r.yg)("strong",{parentName:"li"},"training")," implementation.")),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Phase"),(0,r.yg)("th",{parentName:"tr",align:null},"Pick \u2265 1 backend"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"Inference"),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"vllm"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"sglang"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"Training"),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"DeepSpeed"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"Megatron"))))),(0,r.yg)("hr",null),(0,r.yg)("h2",{id:"1-inference-strategies"},"1. Inference Strategies"),(0,r.yg)("h3",{id:"11-vllm"},"1.1 ",(0,r.yg)("inlineCode",{parentName:"h3"},"vllm")),(0,r.yg)("p",null,"Follow the official guide:",(0,r.yg)("br",{parentName:"p"}),"\n",(0,r.yg)("a",{parentName:"p",href:"https://docs.vllm.ai/en/latest/contributing/model/registration.html#out-of-tree-models"},"https://docs.vllm.ai/en/latest/contributing/model/registration.html#out-of-tree-models")),(0,r.yg)("h3",{id:"12-sglang"},"1.2 ",(0,r.yg)("inlineCode",{parentName:"h3"},"sglang")),(0,r.yg)("p",null,"Follow the official guide:",(0,r.yg)("br",{parentName:"p"}),"\n",(0,r.yg)("a",{parentName:"p",href:"https://docs.sglang.ai/supported_models/support_new_models.html"},"https://docs.sglang.ai/supported_models/support_new_models.html")),(0,r.yg)("hr",null),(0,r.yg)("h2",{id:"2-training-strategies"},"2. Training Strategies"),(0,r.yg)("h3",{id:"21-deepspeed"},"2.1 ",(0,r.yg)("inlineCode",{parentName:"h3"},"DeepSpeed")),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Ensure your model can be loaded by  ",(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-python"},"transformers.AutoModelForCausalLM.from_pretrained(...)\n")),"If not, add the model implementation directly to the ROLL repository."),(0,r.yg)("li",{parentName:"ol"},"Make the model inherit from ",(0,r.yg)("inlineCode",{parentName:"li"},"transformers.PreTrainedModel"),"."),(0,r.yg)("li",{parentName:"ol"},"Make the model can be loaded in ",(0,r.yg)("inlineCode",{parentName:"li"},"roll/models/model_providers.py"),".")),(0,r.yg)("p",null,"Once these steps are complete, you can:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"train with the ",(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_train")," strategy for ",(0,r.yg)("inlineCode",{parentName:"li"},"actor_train")," worker, and  "),(0,r.yg)("li",{parentName:"ul"},"with ",(0,r.yg)("inlineCode",{parentName:"li"},"hf_infer")," or ",(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_infer")," strategy for the ",(0,r.yg)("inlineCode",{parentName:"li"},"reference")," worker.")),(0,r.yg)("h3",{id:"22-megatron"},"2.2 ",(0,r.yg)("inlineCode",{parentName:"h3"},"Megatron")),(0,r.yg)("p",null,"To integrate a Hugging Face model with the ",(0,r.yg)("inlineCode",{parentName:"p"},"Megatron")," training strategy, you need to provide a conversion template. This template defines how to map the model's configuration and weights from the Hugging Face format to the Megatron-Core format."),(0,r.yg)("h4",{id:"1-for-standard-transformer-models"},"1. For Standard Transformer Models"),(0,r.yg)("p",null,"If your model has a standard Transformer architecture compatible with ",(0,r.yg)("inlineCode",{parentName:"p"},"mcore.GPTModel"),", you only need to register a new conversion template. All templates are located in ",(0,r.yg)("inlineCode",{parentName:"p"},"mcore_adapter/src/mcore_adapter/models/converter/template.py"),"."),(0,r.yg)("p",null,"To add a new template, you'll call the ",(0,r.yg)("inlineCode",{parentName:"p"},"register_template")," function at the end of this file. Here\u2019s a detailed guide on how to construct the arguments for this function."),(0,r.yg)("h5",{id:"registering-a-new-template"},"Registering a New Template"),(0,r.yg)("p",null,"The core of the integration is the ",(0,r.yg)("inlineCode",{parentName:"p"},"register_template")," function. Let's break down its main parameters:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"register_template(\n    hf_model_type,\n    config_hf_to_mca,\n    weight_converters,\n    hf_layer_prefix,\n    constant_mca_config={},\n    hf_invalid_keys=[],\n    ...\n)\n")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"a. ",(0,r.yg)("inlineCode",{parentName:"strong"},"hf_model_type")," (str):"),"\nThis is the most crucial parameter. It must exactly match the ",(0,r.yg)("inlineCode",{parentName:"p"},"model_type")," field in the model's Hugging Face ",(0,r.yg)("inlineCode",{parentName:"p"},"config.json")," file. The converter uses this string to look up the correct template."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"b. ",(0,r.yg)("inlineCode",{parentName:"strong"},"hf_layer_prefix")," (str):"),"\nThis specifies the prefix for the transformer layers in the Hugging Face model's state dictionary. For most models, this will be something like ",(0,r.yg)("inlineCode",{parentName:"p"},'"model.layers."'),"."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"c. ",(0,r.yg)("inlineCode",{parentName:"strong"},"config_hf_to_mca")," (Dict","[str, str]","):"),"\nThis dictionary maps configuration parameter names from the Hugging Face ",(0,r.yg)("inlineCode",{parentName:"p"},"config.json")," to their corresponding names in the Megatron-Core ",(0,r.yg)("inlineCode",{parentName:"p"},"TransformerConfig"),"."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"d. ",(0,r.yg)("inlineCode",{parentName:"strong"},"weight_converters")," (List","[ConverOp]","):"),"\nThis is a list of converter operations that define how to transform weights from the HF format to the MCA format. Each operation is an instance of a ",(0,r.yg)("inlineCode",{parentName:"p"},"ConverOp")," subclass."),(0,r.yg)("p",null,"Common converter operations include:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"RenameConverOp")),": Used for weights that only need to be renamed.",(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-python"},"# Renames 'lm_head.weight' in HF to 'output_layer.weight' in MCA\nRenameConverOp(hf_names=\"lm_head.weight\", mca_names=\"output_layer.weight\")\n"))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"StackConverOp")),": Stacks multiple HF tensors into a single MCA tensor. This is commonly used for the gate and up projections in SwiGLU layers.",(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# Stacks two HF weights into one MCA weight for the first feed-forward layer\nStackConverOp(\n    hf_names=[".mlp.gate_proj.weight", ".mlp.up_proj.weight"], \n    mca_names=".mlp.linear_fc1.weight", \n    dim=0\n)\n'))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"QKVConverOp")),": Fuses the separate Query, Key, and Value weight tensors from HF into a single, interleaved QKV tensor required by Megatron-Core.",(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# Fuses Q, K, and V weights into a single QKV weight\nQKVConverOp(\n    hf_names=[".self_attn.q_proj.weight", ".self_attn.k_proj.weight", ".self_attn.v_proj.weight"],\n    mca_names=".self_attention.linear_qkv.weight",\n)\n')))),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"e. ",(0,r.yg)("inlineCode",{parentName:"strong"},"constant_mca_config")," (Dict","[str, Any]","):"),"\nThis dictionary defines Megatron-Core configuration values that are constant for the model and are not available in the HF config."),(0,r.yg)("h4",{id:"2-for-models-with-custom-components"},"2. For Models with Custom Components"),(0,r.yg)("p",null,"If the model includes unique components not found in a standard ",(0,r.yg)("inlineCode",{parentName:"p"},"mcore.GPTModel")," (e.g., Vision Transformer blocks in a multimodal model like Qwen2-VL), you will need to:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Implement a new model class that inherits from ",(0,r.yg)("inlineCode",{parentName:"li"},"mcore.GPTModel")," and adds the custom logic. You can use the implementations for ",(0,r.yg)("inlineCode",{parentName:"li"},"qwen2-vl")," and ",(0,r.yg)("inlineCode",{parentName:"li"},"qwen2.5-vl")," in the repository as a reference."),(0,r.yg)("li",{parentName:"ol"},"Register a template for the parts of the model that are standard, as described above. The template can also handle renaming for the custom parts (e.g., ",(0,r.yg)("inlineCode",{parentName:"li"},'RenameConverOp(hf_names="visual.{}", mca_names="vision_model.{}")'),").")),(0,r.yg)("p",null,"After completing these steps, you can:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"train with the ",(0,r.yg)("inlineCode",{parentName:"li"},"megatron_train")," strategy for the ",(0,r.yg)("inlineCode",{parentName:"li"},"actor_train")," worker, and"),(0,r.yg)("li",{parentName:"ul"},"use the ",(0,r.yg)("inlineCode",{parentName:"li"},"megatron_infer")," strategy for the ",(0,r.yg)("inlineCode",{parentName:"li"},"reference")," worker.")))}d.isMDXComponent=!0},5680:(e,n,t)=>{t.d(n,{xA:()=>g,yg:()=>c});var a=t(6540);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach(function(n){r(e,n,t[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},g=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},y=a.forwardRef(function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,g=l(e,["components","mdxType","originalType","parentName"]),m=p(t),y=r,c=m["".concat(s,".").concat(y)]||m[y]||d[y]||o;return t?a.createElement(c,i(i({ref:n},g),{},{components:t})):a.createElement(c,i({ref:n},g))});function c(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=y;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[m]="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}y.displayName="MDXCreateElement"}}]);